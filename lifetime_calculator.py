import pandas as pd
import numpy as np 
# from konlpy.tag import Okt # KoNLPyëŠ” í˜„ì¬ ì˜¤ë¥˜ë¡œ ì¸í•´ ì£¼ì„ ì²˜ë¦¬

# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
df = pd.read_csv('all_word_trends.csv', index_col='date', parse_dates=True)
df = df.fillna(0) # ê²°ì¸¡ê°’(NaN)ì„ 0ìœ¼ë¡œ ì±„ì›€

# 'isPartial' ì»¬ëŸ¼ì€ ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ì œê±° (ì»¬ëŸ¼ëª…ì´ ìˆë‹¤ë©´)
if 'isPartial' in df.columns:
    df = df.drop(columns=['isPartial'])

# 2. ë°ì´í„° ë¡œë“œ í™•ì¸
print("--- ë°ì´í„° ë¡œë“œ ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í™•ì¸ ---")
print(df.head())
print(df.shape)
print(df.isnull().sum()) 

# 3. ìˆ˜ëª… (Yì¶•) ê³„ì‚° ë° ë¼ë²¨ë§
lifetime_data = {}
feature_data = [] # Xì¶• í”¼ì³ ë°ì´í„°ë¥¼ ëª¨ì„ ë¦¬ìŠ¤íŠ¸

for column in df.columns:
    series = df[column]
    
    # 3-1. ì •ì (Peak) ì°¾ê¸°
    peak_value = series.max()
    peak_date_index = series.idxmax()
    
    # 3-2. ë‹¨ì–´ ê¸¸ì´ (X í”¼ì³ 1)
    word = column.replace(" ", "") # ê³µë°± ì œê±° í›„ ê¸¸ì´ ê³„ì‚°
    word_len = len(word)
    
    # 3-3. ìµœëŒ€ ê´€ì‹¬ë„ê°€ 0ì¸ ê²½ìš° (ìˆ˜ì§‘ ì‹¤íŒ¨ ë˜ëŠ” ìœ í–‰ ì—†ìŒ)
    if peak_value == 0:
        lifetime_data[column] = 0 # ìˆ˜ëª… 0ìœ¼ë¡œ ì²˜ë¦¬
        
        feature_data.append({
            'Word': column, 
            'Word_Length': word_len, 
            'Max_Rising_Slope': 0.0,
            'Total_Active_Months_Raw': 0.0 
        })
        continue # ë‹¤ìŒ ë‹¨ì–´ë¡œ ì´ë™

    # 4. í”¼ì³(Xì¶•) ê³„ì‚°
    
    # 4-1. ìœ í–‰ ì‹œì‘ì (Start) ì°¾ê¸° (10% ì„ê³„ê°’)
    start_threshold = peak_value * 0.1
    start_index = series[series >= start_threshold].first_valid_index()
    
    # 4-2. ìœ í–‰ ì†Œë©¸ì (End) ì„ê³„ê°’ (5% ì„ê³„ê°’)
    end_threshold = peak_value * 0.05
            
    # 4-3. ìµœëŒ€ ìƒìŠ¹ ê¸°ìš¸ê¸° (X í”¼ì³ 2)
    max_rising_slope = 0.0
    if start_index is not None and start_index < peak_date_index:
        rising_period = series.loc[start_index:peak_date_index]
        if len(rising_period) > 1:
            max_slope = rising_period.diff().max()
            if not pd.isna(max_slope):
                max_rising_slope = max(0.0, max_slope)
    
    # 4-4. [ì‹ ê·œ] ì´ í™œì„± ê°œì›” ìˆ˜ (X í”¼ì³ 3)
    total_active_months_raw = (series > 0).sum()
    
    
    # 5. ğŸ”½ [ìˆ˜ì •ë¨] ìˆ˜ëª… (Lifetime - Yì¶•) ê³„ì‚°
    lifetime_months = 0
    lifetime_status = 0 # 0: ì†Œë©¸ (ê¸°ë³¸ê°’)
    end_index = None
    
    if start_index is not None:
        # [ìˆ˜ì •] 'ì‹œì‘ì ' ì´í›„ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
        after_start_series = series[series.index >= start_index]
        
        # [ìˆ˜ì •] 5% ì„ê³„ê°’ ì•„ë˜ë¡œ ë–¨ì–´ì§„ 'ì²« ë²ˆì§¸' ì§€ì ì„ end_indexë¡œ ì„¤ì • (ë‹¨ìˆœ ë¡œì§)
        end_index = after_start_series[after_start_series < end_threshold].first_valid_index()
    
        if start_index and end_index:
            # ê¸°ê°„ ì°¨ì´ë¥¼ ê°œì›” ìˆ˜ë¡œ ë³€í™˜
            lifetime_months = (end_index.year - start_index.year) * 12 + (end_index.month - start_index.month)
            lifetime_status = max(0, lifetime_months)
        else:
            # end_indexë¥¼ ëª»ì°¾ìŒ (ì•„ì§ ì†Œë©¸ ì•ˆë¨)
            lifetime_status = 'Ongoing' 
    else:
        # start_indexê°€ None (ìœ í–‰ ì‹œì‘ì  ë¶ˆëª…) -> ìˆ˜ëª… 0 ì²˜ë¦¬
        lifetime_status = 0
            
    # Yì¶• ë°ì´í„° ì €ì¥
    lifetime_data[column] = lifetime_status 

    # Xì¶• í”¼ì³ ë°ì´í„° ì €ì¥
    feature_data.append({
        'Word': column, 
        'Word_Length': word_len, 
        'Max_Rising_Slope': max_rising_slope,
        'Total_Active_Months_Raw': total_active_months_raw
    })

# 6. ê²°ê³¼ ì¶œë ¥ ë° í•©ì¹˜ê¸°
lifetime_df = pd.DataFrame(lifetime_data.items(), columns=['Word', 'Lifetime (Months)'])
feature_df = pd.DataFrame(feature_data)

# 'Word'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‘ DataFrame ë³‘í•©
final_dataset = pd.merge(lifetime_df, feature_df, on='Word')

# 7. CSV íŒŒì¼ë¡œ ì €ì¥
output_file = 'final_training_dataset.csv'
final_dataset.to_csv(output_file, index=False, encoding='utf-8-sig')

print(f"\n--- ìµœì¢… í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ (v2) ---")
print(final_dataset.head())
print(f"âœ… ë°ì´í„°ê°€ {output_file} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")