import streamlit as st
import speech_recognition as sr
import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsRegressor
import time
from pytrends.request import TrendReq
import datetime 

def load_css(file_name):
    try:
        with open(file_name) as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    except FileNotFoundError:
        st.error(f"âŒ ERROR: 'style.css' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. app.pyì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

st.set_page_config(page_title="ë‹¨ì–´ ë©¸ë§ ì‹œê³„", layout="centered")
load_css("style.css")

# --- 1. ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ (Streamlit ìºì‹± ì‚¬ìš©) ---
@st.cache_resource
def load_model_and_data():
    try:
        df = pd.read_csv('final_training_dataset.csv')
        df_train = df[df['Lifetime (Months)'] != 'Ongoing'].copy()
        
        # 'Max_Rising_Slope'ì— ê²°ì¸¡ì¹˜(NaN)ê°€ ìˆìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€
        df_train['Max_Rising_Slope'] = df_train['Max_Rising_Slope'].fillna(0)
        
        # Yì¶•: ìˆ˜ëª… (ìˆ«ìí˜•)
        Y_train = df_train['Lifetime (Months)'].astype(int)
        
        # ğŸ”½ Xì¶•: ì…ë ¥ í”¼ì³ (ë³€ê²½ë¨)
        X_train = df_train[['Max_Rising_Slope']] 
        
        knn_model = KNeighborsRegressor(n_neighbors=3)
        knn_model.fit(X_train, Y_train)
        
        return knn_model, df_train
        
    except FileNotFoundError:
        st.error("âŒ ERROR: 'final_training_dataset.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. lifetime_calculator.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return None, None
    except Exception as e:
        st.error(f"âŒ ERROR: ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

# --- 2. [ì‹ ê·œ] ì‹¤ì‹œê°„ 'ìµœëŒ€ ìƒìŠ¹ ê¸°ìš¸ê¸°' ê³„ì‚° í•¨ìˆ˜ ---
def calculate_realtime_slope(word_series, word):
    """
    pytrendsë¡œ ê°€ì ¸ì˜¨ ì‹¤ì‹œê°„ pandas.Seriesë¥¼ ë¶„ì„í•˜ì—¬ 
    'ìµœëŒ€ ìƒìŠ¹ ê¸°ìš¸ê¸°(Max_Rising_Slope)'ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    (lifetime_calculator.py ë¡œì§ ê¸°ë°˜)
    """
    try:
        # 1. ì •ì (Peak) ì°¾ê¸°
        peak_value = word_series.max()
        if peak_value == 0:
            return 0.0 # ìœ í–‰ ê¸°ë¡ ì—†ìŒ
        
        peak_date_index = word_series.idxmax()

        # 2. ìœ í–‰ ì‹œì‘ì (Start) ì°¾ê¸°
        start_threshold = peak_value * 0.1 # ìµœëŒ€ì¹˜ì˜ 10%
        start_index = word_series[word_series >= start_threshold].first_valid_index()

        # 3. ìµœëŒ€ ìƒìŠ¹ ê¸°ìš¸ê¸° ê³„ì‚°
        max_rising_slope = 0.0 # ê¸°ë³¸ê°’
        
        if start_index is not None and start_index < peak_date_index:
            # ìƒìŠ¹ êµ¬ê°„ (ì‹œì‘ì  ~ ì •ì )
            rising_period = word_series.loc[start_index:peak_date_index]
            
            if len(rising_period) > 1:
                # ì›”ë³„ ê´€ì‹¬ë„ ë³€í™”ìœ¨(diff)ì˜ ìµœëŒ€ê°’
                max_slope = rising_period.diff().max()
                
                # NaNì´ ì•„ë‹ ê²½ìš°ì—ë§Œ ê°’ í• ë‹¹
                if not pd.isna(max_slope):
                    max_rising_slope = max_slope
        
        # 0ë³´ë‹¤ ì‘ì€ ê°’ì€ 0ìœ¼ë¡œ ì²˜ë¦¬ (í•˜ë½ì€ ë¬´ì‹œ)
        return max(0.0, max_rising_slope)

    except Exception as e:
        st.error(f"'{word}' ê¸°ìš¸ê¸° ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.0 # ì˜¤ë¥˜ ì‹œ 0 ë°˜í™˜

# --- 3. [ìˆ˜ì •ë¨] ì˜ˆì¸¡ í•¨ìˆ˜ (ê¸°ìš¸ê¸° ê°’ì„ Xë¡œ ë°›ìŒ) ---
def predict_lifetime(model, df_train, slope_value):
    """
    ê³„ì‚°ëœ 'ê¸°ìš¸ê¸°' ê°’ì„ ë°›ì•„ k-NN ëª¨ë¸ë¡œ ìˆ˜ëª…ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
    # 1. X í”¼ì³ ìƒì„± (DataFrame í˜•íƒœ)
    X_pred = pd.DataFrame({'Max_Rising_Slope': [slope_value]})
    
    # 2. k-NN ëª¨ë¸ë¡œ ì˜ˆì¸¡
    predicted_lifetime = model.predict(X_pred)
    
    # 3. ì˜ˆì¸¡ê°’ ë°˜í™˜ (ì •ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼)
    final_months = int(round(predicted_lifetime[0]))
    
    # 4. ì˜ˆì¸¡ì— ì‚¬ìš©ëœ 'ê°€ê¹Œìš´' ë‹¨ì–´(ì´ì›ƒ) ì°¾ê¸°
    distances, indices = model.kneighbors(X_pred)
    nearby_words = df_train.iloc[indices[0]]['Word'].tolist()

    return final_months, nearby_words


# --- 4. ìŒì„± ì¸ì‹ ì½œë°± í•¨ìˆ˜ (STT) (ê¸°ì¡´ê³¼ ë™ì¼) ---
def on_stt_button_click():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("ğŸ¤ ë§ˆì´í¬ì— ëŒ€ê³  ë§ì”€í•˜ì„¸ìš”... (3ì´ˆê°„ ë…¹ìŒ)")
        try:
            r.adjust_for_ambient_noise(source, duration=0.5)
            audio = r.listen(source, timeout=5, phrase_time_limit=3)
            
            # STT (Google)
            text = r.recognize_google(audio, language='ko-KR')
            st.session_state.text = text # ì„¸ì…˜ì— ì €ì¥
            st.success(f"âœ… \"{text}\" ìŒì„± ì¸ì‹ ì„±ê³µ!")
            
        except sr.WaitTimeoutError:
            st.warning("âš ï¸ ìŒì„± ì…ë ¥ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except sr.UnknownValueError:
            st.error("âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except sr.RequestError as e:
            st.error(f"âŒ Google STT ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {e}")
        except Exception as e:
            st.error(f"âŒ STT ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")

def main():
    load_css("style.css")
    st.video("img/smoke.mp4", start_time=0)
    st.markdown('<h1 class="title-text"><span>â˜¯ï¸ë‹¨ì–´ ë©¸ë§ ì‹œê³„â˜¯ï¸</span></h1>', unsafe_allow_html=True)
    st.markdown("<p>ìŒì„±ìœ¼ë¡œ ì‹ ì¡°ì–´ë¥¼ ì…ë ¥í•˜ë©´, 'ìµœëŒ€ ìƒìŠ¹ ê¸°ìš¸ê¸°'ë¥¼ ì‹¤ì‹œê°„ ë¶„ì„í•˜ì—¬ ìˆ˜ëª…ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.</p>", unsafe_allow_html=True)

    # 1. ëª¨ë¸ ë¡œë“œ
    knn_model, df_train = load_model_and_data()
    if knn_model is None:
        return # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨

    # 2. STT ë²„íŠ¼
    st.button("Click to Speak", on_click=on_stt_button_click, use_container_width=True)

    # 3. [ìˆ˜ì •ë¨] STT ì™„ë£Œ í›„ 'ì‹¤ì‹œê°„ ë¶„ì„' ë° 'ì˜ˆì¸¡' ë¡œì§
    if "text" in st.session_state and st.session_state.text:
        text = st.session_state.text
        st.markdown(f"<p class='user-input'>ì…ë ¥ëœ ë‹¨ì–´: \"{text}\"</p>", unsafe_allow_html=True)

        realtime_slope = 0.0
        interest_df = None
        
        try:
            # --- (A) [ì‹ ê·œ] ì‹¤ì‹œê°„ Pytrends í˜¸ì¶œ ---
            with st.spinner(f"Google Trendsì—ì„œ '{text}'ì˜ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘..."):
                pytrends = TrendReq(hl='ko-KR', tz=540)
                pytrends.build_payload([text], cat=0, timeframe='all', geo='KR')
                interest_df = pytrends.interest_over_time()

            if interest_df.empty or text not in interest_df.columns:
                st.error(f"'{text}'ì— ëŒ€í•œ Google Trends ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                del st.session_state.text # ì„¸ì…˜ ì´ˆê¸°í™”
                return # ì¤‘ë‹¨

            # --- (B) [ì‹ ê·œ] ì‹¤ì‹œê°„ ê¸°ìš¸ê¸° ê³„ì‚° ---
            word_series = interest_df[text]
            realtime_slope = calculate_realtime_slope(word_series, text)
            
            st.success(f"âœ… '{text}'ì˜ 'ìµœëŒ€ ìƒìŠ¹ ê¸°ìš¸ê¸°' ê³„ì‚° ì™„ë£Œ: **{realtime_slope:.2f}**")
            
            # (ì„ íƒ) ì‹¤ì‹œê°„ ì°¨íŠ¸ í‘œì‹œ
            st.line_chart(word_series)

            # --- (C) [ìˆ˜ì •ë¨] ê¸°ìš¸ê¸° ê¸°ë°˜ ì˜ˆì¸¡ ---
            predicted_months, nearby_words_list = predict_lifetime(knn_model, df_train, realtime_slope)

            # --- (D) [ê¸°ì¡´] ì¹´ìš´íŠ¸ë‹¤ìš´ ë¡œì§ (ë™ì¼í•˜ê²Œ ì‚¬ìš©) ---
            
            # ê²°ê³¼ ë©”ì‹œì§€ ì„¤ì • (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
            result_message = f"{predicted_months} ê°œì›”"
            status_text = "ğŸ“ˆ ì•„ì§ ìƒëª…ë ¥ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤." # (ê¸°ì¡´ ë¡œì§ ë‹¨ìˆœí™”)
            
            # 1. ìˆ«ìê°€ í‘œì‹œë  ë¹ˆ ê³µê°„(Placeholder) ìƒì„±
            result_placeholder = st.empty()
            
            # 2. ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘ (ì˜ˆ: 60ë¶€í„°)
            start_tick = 60 
            
            # 3. 60ë¶€í„° ì˜ˆì¸¡ëœ ìˆ˜ëª…(predicted_months)ê¹Œì§€ 1ì”© ê°ì†Œ
            # (ìˆ˜ì •: start_tickë³´ë‹¤ ì˜ˆì¸¡ ìˆ˜ëª…ì´ í¬ë©´ start_tickì—ì„œ ì‹œì‘, ì•„ë‹ˆë©´ ì˜ˆì¸¡ìˆ˜ëª…+10 ì—ì„œ ì‹œì‘)
            if predicted_months > start_tick:
                start_point = start_tick
            else:
                start_point = max(predicted_months + 10, predicted_months) # ìµœì†Œ 10ë²ˆì€ ëŒë„ë¡
            
            for i in range(start_point, predicted_months - 1, -1):
                result_placeholder.markdown(
                    f"<div class=\"result-text\">{i}</div>", 
                    unsafe_allow_html=True
                )
                time.sleep(0.05) # 0.05ì´ˆ ê°„ê²©

            # 4. ì¹´ìš´íŠ¸ë‹¤ìš´ ì™„ë£Œ í›„ ìµœì¢… ê²°ê³¼ ë©”ì‹œì§€ ê³ ì •
            result_placeholder.markdown(
                f"<div class=\"result-text\">{result_message}</div>", 
                unsafe_allow_html=True
            )
            
            # ë””íœìŠ¤ ë…¼ë¦¬ ì„¤ëª…
            st.markdown(f'<p class="sub-text" style="color: #AAA;">{status_text}</p>', unsafe_allow_html=True)
            st.markdown(f"""
                <p style='font-size: 16px; color: #E0E0E0;'>
                ì´ ì˜ˆì¸¡ì€ <b>'{text}'</b>ì˜ ì‹¤ì‹œê°„ ìµœëŒ€ ìƒìŠ¹ ê¸°ìš¸ê¸° (<b>{realtime_slope:.2f}</b>)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ,
                í›ˆë ¨ ë°ì´í„°ì…‹ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ê¸°ìš¸ê¸°ë¥¼ ê°€ì§„ ë‹¨ì–´ë“¤
                (ì˜ˆ: <b>{', '.join(nearby_words_list)}</b>)ì˜ í‰ê·  ìˆ˜ëª…ì„ ê³„ì‚°í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
                </p>
            """, unsafe_allow_html=True)


        except Exception as e:
            if "429" in str(e):
                st.error("âŒ Google Trends ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                st.error(f"âŒ ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        del st.session_state.text

if __name__ == "__main__":
    main()

st.markdown("""
<div class="fog-container">
  <div class="fog-img fog-img-first"></div>
  <div class="fog-img fog-img-second"></div>
</div>
""", unsafe_allow_html=True)
